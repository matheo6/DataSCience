{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taller Redes Neuronales MB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONhbEMVE1ULdywoFzTfpLo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheo6/DataSCience/blob/master/NeuronalNetwork/Taller_Redes_Neuronales_MB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RkyhYemk1km",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "fdaf4072-00dc-4173-db78-e3c3adf3f76a"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon Feb 18 07:39:24 2019\n",
        "\n",
        "@author: Nelson\n",
        "\"\"\"\n",
        "\n",
        "\t\n",
        "import sklearn\n",
        " \n",
        "## import the iris dataset for classification\n",
        " \n",
        "from sklearn import datasets\n",
        "#Data set a usar\n",
        "iris=sklearn.datasets.load_digits()\n",
        "\n",
        "## print some data, to see the imported dataset\n",
        " \n",
        "print(\"Se muestran los ultimo 5 registros del data set\")\n",
        "for training_sample in list(zip(iris.data,iris.target))[:5]:\n",
        "    print(training_sample)\n",
        " ## save the features and class\n",
        " \n",
        "features=iris.data   # split iris dataset into features and iris_class\n",
        "iris_class=iris.target  # class[X] is output corresponding to features[X]\n",
        " \n",
        "## Split the dataset into training (70%) and testing (30%)\n",
        "## Note that the shuffle parameter has been used in splitting.\n",
        " \n",
        "print(\"Splitting the data into testing and training samples\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "features_train, features_test,iris_class_train, iris_class_test = train_test_split(features,iris_class, test_size=0.33, random_state=42)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se muestran los ultimo 5 registros del data set\n",
            "(array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
            "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
            "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
            "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
            "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.]), 0)\n",
            "(array([ 0.,  0.,  0., 12., 13.,  5.,  0.,  0.,  0.,  0.,  0., 11., 16.,\n",
            "        9.,  0.,  0.,  0.,  0.,  3., 15., 16.,  6.,  0.,  0.,  0.,  7.,\n",
            "       15., 16., 16.,  2.,  0.,  0.,  0.,  0.,  1., 16., 16.,  3.,  0.,\n",
            "        0.,  0.,  0.,  1., 16., 16.,  6.,  0.,  0.,  0.,  0.,  1., 16.,\n",
            "       16.,  6.,  0.,  0.,  0.,  0.,  0., 11., 16., 10.,  0.,  0.]), 1)\n",
            "(array([ 0.,  0.,  0.,  4., 15., 12.,  0.,  0.,  0.,  0.,  3., 16., 15.,\n",
            "       14.,  0.,  0.,  0.,  0.,  8., 13.,  8., 16.,  0.,  0.,  0.,  0.,\n",
            "        1.,  6., 15., 11.,  0.,  0.,  0.,  1.,  8., 13., 15.,  1.,  0.,\n",
            "        0.,  0.,  9., 16., 16.,  5.,  0.,  0.,  0.,  0.,  3., 13., 16.,\n",
            "       16., 11.,  5.,  0.,  0.,  0.,  0.,  3., 11., 16.,  9.,  0.]), 2)\n",
            "(array([ 0.,  0.,  7., 15., 13.,  1.,  0.,  0.,  0.,  8., 13.,  6., 15.,\n",
            "        4.,  0.,  0.,  0.,  2.,  1., 13., 13.,  0.,  0.,  0.,  0.,  0.,\n",
            "        2., 15., 11.,  1.,  0.,  0.,  0.,  0.,  0.,  1., 12., 12.,  1.,\n",
            "        0.,  0.,  0.,  0.,  0.,  1., 10.,  8.,  0.,  0.,  0.,  8.,  4.,\n",
            "        5., 14.,  9.,  0.,  0.,  0.,  7., 13., 13.,  9.,  0.,  0.]), 3)\n",
            "(array([ 0.,  0.,  0.,  1., 11.,  0.,  0.,  0.,  0.,  0.,  0.,  7.,  8.,\n",
            "        0.,  0.,  0.,  0.,  0.,  1., 13.,  6.,  2.,  2.,  0.,  0.,  0.,\n",
            "        7., 15.,  0.,  9.,  8.,  0.,  0.,  5., 16., 10.,  0., 16.,  6.,\n",
            "        0.,  0.,  4., 15., 16., 13., 16.,  1.,  0.,  0.,  0.,  0.,  3.,\n",
            "       15., 10.,  0.,  0.,  0.,  0.,  0.,  2., 16.,  4.,  0.,  0.]), 4)\n",
            "Splitting the data into testing and training samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZVvCvm4lFcQ",
        "colab_type": "text"
      },
      "source": [
        "**Las sentencias a continuacion muestra como se escala y se preparan los datos para el entrenamiento del dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23AAl2rylpSt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6c1c4abe-e3fe-463f-e378-8179d9f875f0"
      },
      "source": [
        "## data preprocessing: Before training the network we must scale the feature data\n",
        "print(\"Data preprocessing\")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(features_train)\n",
        "features_train_scale = scaler.transform(features_train)\n",
        "features_test_scale = scaler.transform(features_test)\n",
        "for x in list(zip(features_train, features_train_scale))[:5]:\n",
        "    print(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data preprocessing\n",
            "(array([ 0.,  0.,  0.,  1., 12.,  7.,  0.,  0.,  0.,  0.,  0.,  9., 16.,\n",
            "       16.,  1.,  0.,  0.,  1.,  7., 15., 16., 14.,  0.,  0.,  0.,  4.,\n",
            "       16., 16., 16., 16.,  0.,  0.,  0.,  0.,  0.,  3., 16., 16.,  0.,\n",
            "        0.,  0.,  0.,  0.,  2., 16., 16.,  3.,  0.,  0.,  0.,  0.,  6.,\n",
            "       16., 16.,  0.,  0.,  0.,  0.,  0.,  3., 15., 13.,  0.,  0.]), array([ 0.        , -0.35276262, -1.07887239, -2.51619757,  0.03683937,\n",
            "        0.23125775, -0.39446536, -0.12830245, -0.05478595, -0.62236025,\n",
            "       -1.85430728, -0.75646051,  1.17486846,  1.26844605, -0.236466  ,\n",
            "       -0.13525536, -0.05456747, -0.43252474, -0.4728276 ,  1.33828193,\n",
            "        1.43517592,  0.99283946, -0.55039331, -0.10829185, -0.04080783,\n",
            "        0.56456251,  1.14440881,  1.21756841,  1.00102024,  1.44571927,\n",
            "       -0.61761261, -0.04080783,  0.        , -0.65031291, -1.20984229,\n",
            "       -0.98011763,  0.96171804,  1.2622624 , -0.8037801 ,  0.        ,\n",
            "       -0.07127841, -0.52169715, -1.06621948, -0.84186706,  1.31485839,\n",
            "        1.37151081, -0.10249068, -0.09664544, -0.04025169, -0.41602807,\n",
            "       -1.34402537, -0.70749028,  1.23614902,  1.19308639, -0.75916372,\n",
            "       -0.21870851, -0.02884349, -0.31805598, -1.07580565, -2.04379217,\n",
            "        0.64002019,  1.06058522, -0.505317  , -0.19535349]))\n",
            "(array([ 0.,  0.,  1., 15., 15.,  2.,  0.,  0.,  0.,  0.,  0., 12., 16.,\n",
            "        7.,  0.,  0.,  0.,  0.,  0., 14., 16.,  5.,  0.,  0.,  0.,  0.,\n",
            "        0., 13., 16.,  2.,  0.,  0.,  0.,  0.,  2., 16., 13.,  0.,  0.,\n",
            "        0.,  0.,  0.,  6., 16., 13.,  0.,  0.,  0.,  0.,  0.,  6., 16.,\n",
            "       11.,  0.,  0.,  0.,  0.,  0.,  1., 14., 16.,  7.,  0.,  0.]), array([ 0.        , -0.35276262, -0.87246598,  0.7376261 ,  0.74029594,\n",
            "       -0.66675088, -0.39446536, -0.12830245, -0.05478595, -0.62236025,\n",
            "       -1.85430728, -0.00479036,  1.17486846, -0.19802116, -0.51291751,\n",
            "       -0.13525536, -0.05456747, -0.71332737, -1.70174156,  1.16724685,\n",
            "        1.43517592, -0.46689341, -0.55039331, -0.10829185, -0.04080783,\n",
            "       -0.76518531, -1.42950808,  0.71056432,  1.00102024, -0.93255812,\n",
            "       -0.61761261, -0.04080783,  0.        , -0.65031291, -0.891156  ,\n",
            "        1.0881673 ,  0.45413681, -1.4618128 , -0.8037801 ,  0.        ,\n",
            "       -0.07127841, -0.52169715, -0.14718769,  1.33947525,  0.83524206,\n",
            "       -1.4365777 , -0.78747008, -0.09664544, -0.04025169, -0.41602807,\n",
            "       -0.28425094,  1.21809978,  0.27375757, -1.46484496, -0.75916372,\n",
            "       -0.21870851, -0.02884349, -0.31805598, -0.88330316,  0.44498135,\n",
            "        0.84655031,  0.03591595, -0.505317  , -0.19535349]))\n",
            "(array([ 0.,  1., 12., 15., 16., 13.,  1.,  0.,  0.,  4., 16., 15.,  7.,\n",
            "       15.,  4.,  0.,  0.,  0., 16.,  6., 11., 15.,  2.,  0.,  0.,  0.,\n",
            "        9., 16., 15.,  4.,  0.,  0.,  0.,  0.,  8., 16.,  8.,  0.,  0.,\n",
            "        0.,  0.,  0., 15., 15., 11.,  0.,  0.,  0.,  0.,  2., 16., 10.,\n",
            "       12.,  0.,  0.,  0.,  0.,  2., 13., 16., 10.,  0.,  0.,  0.]), array([ 0.        ,  0.72432731,  1.39800449,  0.7376261 ,  0.97478146,\n",
            "        1.3088681 , -0.09506988, -0.12830245, -0.05478595,  0.59801364,\n",
            "        1.05076406,  0.74687978, -0.7155017 ,  1.10550525,  0.59288852,\n",
            "       -0.13525536, -0.05456747, -0.71332737,  1.10720463, -0.20103375,\n",
            "        0.62589654,  1.15503201,  0.05761693, -0.10829185, -0.04080783,\n",
            "       -0.76518531,  0.01832017,  1.21756841,  0.83933558, -0.59280421,\n",
            "       -0.61761261, -0.04080783,  0.        , -0.65031291,  0.06490286,\n",
            "        1.0881673 , -0.39183189, -1.4618128 , -0.8037801 ,  0.        ,\n",
            "       -0.07127841, -0.52169715,  1.23136   ,  1.18366508,  0.51549785,\n",
            "       -1.4365777 , -0.78747008, -0.09664544, -0.04025169,  0.7318659 ,\n",
            "        1.48203977,  0.06274574,  0.46623586, -1.46484496, -0.75916372,\n",
            "       -0.21870851, -0.02884349,  1.90003877,  1.42672663,  0.89748562,\n",
            "       -0.39263041, -1.15953153, -0.505317  , -0.19535349]))\n",
            "(array([ 0.,  0.,  2., 13.,  8.,  0.,  0.,  0.,  0.,  0.,  6., 16., 16.,\n",
            "        6.,  0.,  0.,  0.,  0.,  5., 15., 13., 11.,  0.,  0.,  0.,  0.,\n",
            "        0.,  7., 16., 15.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 14.,  3.,\n",
            "        0.,  0.,  0.,  0.,  0.,  0.,  7., 11.,  0.,  0.,  0.,  0.,  3.,\n",
            "        4.,  4., 16.,  2.,  0.,  0.,  2., 15., 13., 14., 13.,  2.]), array([ 0.        , -0.35276262, -0.66605958,  0.27279415, -0.90110272,\n",
            "       -1.02595433, -0.39446536, -0.12830245, -0.05478595, -0.62236025,\n",
            "       -0.76490553,  0.9974365 ,  1.17486846, -0.36096196, -0.51291751,\n",
            "       -0.13525536, -0.05456747, -0.71332737, -0.82394588,  1.33828193,\n",
            "        0.94960829,  0.50626184, -0.55039331, -0.10829185, -0.04080783,\n",
            "       -0.76518531, -1.42950808, -0.30344384,  1.00102024,  1.27584231,\n",
            "       -0.61761261, -0.04080783,  0.        , -0.65031291, -1.20984229,\n",
            "       -1.45741415, -1.74538181,  0.921753  ,  0.05879569,  0.        ,\n",
            "       -0.07127841, -0.52169715, -1.06621948, -1.15348739, -1.24309535,\n",
            "       -0.20803898,  1.72412105, -0.09664544, -0.04025169, -0.41602807,\n",
            "       -1.34402537, -1.2851673 , -1.07359046, -0.80036212,  2.4765279 ,\n",
            "        1.89459541, -0.02884349, -0.31805598, -0.69080068,  0.67123348,\n",
            "        0.22695995,  1.23136343,  2.63065622,  0.90539707]))\n",
            "(array([ 0.,  2., 11., 14., 14.,  9.,  0.,  0.,  0.,  3., 10.,  7., 10.,\n",
            "       16.,  3.,  0.,  0.,  0.,  0.,  4., 13., 12.,  0.,  0.,  0.,  0.,\n",
            "        0., 13., 15.,  2.,  0.,  0.,  0.,  0.,  0., 15.,  9.,  0.,  0.,\n",
            "        0.,  0.,  0.,  0.,  9., 15.,  0.,  0.,  0.,  0.,  0.,  1., 13.,\n",
            "        9.,  0.,  0.,  0.,  0.,  1., 15., 13.,  1.,  0.,  0.,  0.]), array([ 0.        ,  1.80141724,  1.19159808,  0.50521012,  0.50581042,\n",
            "        0.5904612 , -0.39446536, -0.12830245, -0.05478595,  0.29292017,\n",
            "       -0.03863769, -1.25757394, -0.08537831,  1.26844605,  0.31643701,\n",
            "       -0.13525536, -0.05456747, -0.71332737, -1.70174156, -0.5431039 ,\n",
            "        0.94960829,  0.66845438, -0.55039331, -0.10829185, -0.04080783,\n",
            "       -0.76518531, -1.42950808,  0.71056432,  0.83933558, -0.93255812,\n",
            "       -0.61761261, -0.04080783,  0.        , -0.65031291, -1.20984229,\n",
            "        0.92906846, -0.22263815, -1.4618128 , -0.8037801 ,  0.        ,\n",
            "       -0.07127841, -0.52169715, -1.06621948,  0.2488041 ,  1.15498628,\n",
            "       -1.4365777 , -0.78747008, -0.09664544, -0.04025169, -0.41602807,\n",
            "       -1.1673963 ,  0.64042276, -0.11119901, -1.46484496, -0.75916372,\n",
            "       -0.21870851, -0.02884349,  0.79099139,  1.8117316 ,  0.21872921,\n",
            "       -2.2514015 , -1.15953153, -0.505317  , -0.19535349]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvyYfWizlt2m",
        "colab_type": "text"
      },
      "source": [
        "**se establecen los parametros con los cuales se realizara el entrenamiento de la red neuronal**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNfh3TBal2xG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "48ddb54c-fd85-4ea2-d103-4af05ea45a77"
      },
      "source": [
        " \n",
        "## The MLPClassifier and MLPRegressor are sklearn implementations of NNs\n",
        " \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "iterations=1000   # define the iterations for training over the dataset\n",
        "hidden_layers=[10,10,10]  # define the layers/depth of the NN\n",
        " \n",
        "mlp = MLPClassifier(hidden_layer_sizes=(hidden_layers), max_iter=iterations) \n",
        "print(mlp)\n",
        " "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
            "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
            "              hidden_layer_sizes=[10, 10, 10], learning_rate='constant',\n",
            "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
            "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
            "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
            "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
            "              warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZboRlp3mGDm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "efcbfb36-d797-40a1-882b-0f37b9ac505a"
      },
      "source": [
        "# an object which represents the neural network\n",
        "# Remember to use the pre-processed data and not original values for fit()\n",
        " \n",
        "mlp.fit(features_train_scale, iris_class_train)  # fit features over NN\n",
        " \n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=[10, 10, 10], learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KENFBAtWmJst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "9ee0bc87-e56c-43e2-e117-a8d814e02a9d"
      },
      "source": [
        "## Run the test data over the network to see the predicted outcomes.\n",
        " \n",
        "predicted = mlp.predict(features_test_scale)  \n",
        "print(predicted)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 9 3 7 2 8 5 2 5 3 8 9 4 0 4 2 3 7 8 8 4 3 9 7 5 6 3 5 6 3 4 9 1 4 4 6 9\n",
            " 4 7 6 6 9 1 3 6 1 3 0 6 5 5 1 9 5 6 0 9 0 0 1 7 4 5 2 4 5 7 0 7 5 9 5 5 4\n",
            " 7 0 4 5 5 8 9 0 2 3 8 0 6 4 4 9 1 2 8 3 5 2 9 4 4 4 4 3 5 3 1 3 5 9 4 2 7\n",
            " 7 4 4 1 9 2 7 5 7 2 6 9 4 0 7 2 7 5 8 7 5 7 9 0 6 6 4 2 8 0 9 4 6 9 9 6 9\n",
            " 0 6 5 6 6 0 6 4 8 9 3 8 7 2 3 0 4 5 3 6 5 9 9 8 4 2 1 3 7 7 2 2 3 9 8 0 3\n",
            " 2 2 5 6 9 9 4 1 5 4 2 3 6 4 8 5 9 5 7 8 9 4 8 1 5 4 4 9 6 1 8 6 0 4 5 2 7\n",
            " 4 6 4 5 6 0 3 2 3 6 7 1 9 1 4 7 6 5 8 5 5 1 0 8 8 8 9 9 7 6 2 2 2 3 4 8 8\n",
            " 3 6 0 8 7 7 0 1 0 4 5 1 5 3 6 0 4 1 0 0 3 6 5 9 7 3 5 5 9 9 4 5 3 3 2 0 5\n",
            " 8 3 4 0 8 4 6 4 3 4 5 0 5 2 1 3 1 4 1 1 7 0 1 5 8 1 2 8 7 0 6 4 8 8 5 1 2\n",
            " 4 5 8 7 9 8 5 0 6 2 0 7 9 8 9 5 2 7 7 9 1 7 4 3 8 3 5 6 0 0 3 0 5 0 0 4 1\n",
            " 2 8 4 5 9 6 3 1 8 8 4 2 3 1 9 8 8 5 0 6 3 3 7 1 6 4 4 2 1 1 6 4 9 4 8 3 4\n",
            " 0 5 1 9 4 5 7 6 3 7 0 5 9 7 5 9 7 4 2 1 9 0 7 5 2 3 6 3 4 6 9 5 0 1 5 5 8\n",
            " 3 3 6 2 6 5 6 2 0 8 7 3 7 0 2 2 3 5 8 7 3 6 5 9 9 2 8 6 3 0 7 1 1 9 6 1 8\n",
            " 0 0 2 9 3 9 9 9 7 7 1 3 5 4 6 8 2 1 1 8 7 6 9 2 0 4 4 2 8 7 1 3 1 7 1 8 5\n",
            " 1 7 0 0 2 2 6 9 4 4 9 0 6 7 7 9 5 4 7 0 7 6 8 7 1 4 6 2 8 7 5 9 0 3 9 6 6\n",
            " 1 9 1 2 9 8 9 7 4 8 5 6 9 7 7 6 8 1 3 5 7 9 5 5 2 4 1 2 2 0 1 7 5 8 3 9 4\n",
            " 9 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEV5vqCPmMbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "228312c5-95ea-447d-d6fb-54a5ec410c2d"
      },
      "source": [
        "# predict over test data\n",
        "## evaluation metrics and analysing the accuracy/output.\n",
        "print(\"Evaluation: considering the confusion matrix\")\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(iris_class_test,predicted))  \n",
        "# all non-diagonal elements are 0 if you get 100% accuracy\n",
        " "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation: considering the confusion matrix\n",
            "[[53  0  0  0  1  0  0  1  0  0]\n",
            " [ 0 47  0  0  3  0  0  0  4  1]\n",
            " [ 0  0 48  1  0  0  0  0  3  0]\n",
            " [ 0  0  1 52  0  0  1  0  1  1]\n",
            " [ 1  0  0  0 63  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 69  2  0  1  1]\n",
            " [ 1  0  0  0  0  0 56  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 60  0  2]\n",
            " [ 0  4  2  1  1  2  0  0 42  0]\n",
            " [ 0  0  0  1  1  0  0  0  4 62]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAeIS58lmPUV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "441c67cb-4ed5-4402-f5d3-6d3845662ac1"
      },
      "source": [
        "print(\"Evaluation report:\")\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(iris_class_test,predicted)) \n",
        "#f1-score/accuracy"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96        55\n",
            "           1       0.92      0.85      0.89        55\n",
            "           2       0.94      0.92      0.93        52\n",
            "           3       0.95      0.93      0.94        56\n",
            "           4       0.91      0.98      0.95        64\n",
            "           5       0.97      0.95      0.96        73\n",
            "           6       0.95      0.98      0.97        57\n",
            "           7       0.98      0.97      0.98        62\n",
            "           8       0.76      0.81      0.79        52\n",
            "           9       0.93      0.91      0.92        68\n",
            "\n",
            "    accuracy                           0.93       594\n",
            "   macro avg       0.93      0.93      0.93       594\n",
            "weighted avg       0.93      0.93      0.93       594\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BitlKnGzmTXo",
        "colab_type": "text"
      },
      "source": [
        "**Precision**: Es la proporción de datos agrupados de manera correcta por tipo de flor en la predicción sobre los aciertos más los errores tomados como ciertos, agrupados en ese tipo de flor.\n",
        "\n",
        "**Recall**: Es la proporción de datos agrupados de manera correcta por tipo de flor en la predicción sobre los aciertos más los aciertos tomados como erores, agrupados en ese tipo de flor.\n",
        "\n",
        "**f1-Score**:: Determina la media ponderada entre la precision y el recall\n",
        "\n",
        "**Support**: Total de muestras por tipo de flor\n",
        "\n",
        "**Acuracy**: Define la exactitud de la clasificación es decir los aciertos correctos sobre la cantidad total de aciertos que deberian ser, los cuales se toman del target.\n",
        "\n",
        "**Macro Avg**: Promedio de alguna columna de medición (precision, recall, f1-score)\n",
        "\n",
        "**Weighted Avg**: Encuentra las métricas para cada etiqueta del dataset, calculando el número de instancias verdadesras para cada una de las etiquetas. texto en negrita**"
      ]
    }
  ]
}